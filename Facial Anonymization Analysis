{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDjqd_voAghZ",
        "outputId": "75fe4a66-e817-441f-817a-f7db44b219a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.79-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.1)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.14.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.14.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.42.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=1f2d7bafece2ff857774eb4ffb4657b867a8548c36412f1fb5cbc9274d076776\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: gunicorn, fire, mtcnn, retina-face, deepface\n",
            "Successfully installed deepface-0.0.79 fire-0.5.0 gunicorn-21.2.0 mtcnn-0.1.1 retina-face-0.0.13\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%pip install deepface\n",
        "%pip install tabulate\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWJUDoee5w8g"
      },
      "outputs": [],
      "source": [
        "class Detector:\n",
        "    def __init__(self, model_path, name=\"\"):\n",
        "        self.graph = tf.Graph()\n",
        "        self.model_path = model_path\n",
        "        self.model_name = name\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.graph_def = tf.compat.v1.GraphDef()\n",
        "            with tf.io.gfile.GFile(model_path, 'rb') as f:\n",
        "                self.graph_def.ParseFromString(f.read())\n",
        "                tf.import_graph_def(self.graph_def, name='')\n",
        "        # print(f\"{self.model_name} model is created..\")\n",
        "\n",
        "    def detect_objects(self, img, threshold=0.3):\n",
        "        \"\"\"Runs the model and returns the object inside it\n",
        "        Args:\n",
        "        img (np_array)    -- input image\n",
        "        threshold (float) -- threshold between (0,1)\n",
        "\n",
        "        Returns:\n",
        "        objects -- object list, each element is a dictionary that has [id, score, x1, y1, x2, y2] keys\n",
        "        Ex: {'id': 16, 'score': 0.11703299731016159, 'x1': 42, 'y1': 6, 'x2': 55, 'y2': 27}\n",
        "        \"\"\"\n",
        "\n",
        "        # print(\n",
        "        #     \"{} : Object detection has started..\".format(self.model_name))\n",
        "\n",
        "        start_time = time.time()\n",
        "        objects = []\n",
        "\n",
        "        # start the session\n",
        "        with tf.compat.v1.Session(graph=self.graph) as sess:\n",
        "\n",
        "            # reshpae input image to give it to the network\n",
        "            rows = img.shape[0]\n",
        "            cols = img.shape[1]\n",
        "            image_np_expanded = np.expand_dims(img, axis=0)\n",
        "\n",
        "            # run the model\n",
        "            (num, scores, boxes,\n",
        "                classes) = self.sess.run(\n",
        "                    [self.sess.graph.get_tensor_by_name('num_detections:0'),\n",
        "                     self.sess.graph.get_tensor_by_name('detection_scores:0'),\n",
        "                     self.sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
        "                     self.sess.graph.get_tensor_by_name('detection_classes:0')],\n",
        "                feed_dict={'image_tensor:0': image_np_expanded})\n",
        "\n",
        "            # parse the results\n",
        "            for i in range(int(num)):\n",
        "                score = float(scores[0, i])\n",
        "                if score > threshold:\n",
        "                    obj = {}\n",
        "                    obj[\"id\"] = int(classes[0, i])\n",
        "                    obj[\"score\"] = score\n",
        "                    bbox = [float(v) for v in boxes[0, i]]\n",
        "                    obj[\"x1\"] = int(bbox[1] * cols)\n",
        "                    obj[\"y1\"] = int(bbox[0] * rows)\n",
        "                    obj[\"x2\"] = int(bbox[3] * cols)\n",
        "                    obj[\"y2\"] = int(bbox[2] * rows)\n",
        "                    objects.append(obj)\n",
        "\n",
        "            # print(f\"{self.model_name} : {len(objects)} objects have been found \")\n",
        "        end_time = time.time()\n",
        "        # print(\"{} : Elapsed time: {}\".format(\n",
        "        #     self.model_name, str(end_time - start_time)))\n",
        "\n",
        "        return objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSuoY-aNBONn"
      },
      "outputs": [],
      "source": [
        "def blur_faces_in_image(input_image, model_path, output_image=None, threshold=0.7):\n",
        "    detector = Detector(model_path=model_path, name=\"detection\")\n",
        "    image = cv2.imread(input_image)\n",
        "    faces = detector.detect_objects(image, threshold=threshold)\n",
        "    for box in faces:\n",
        "        x1, y1 = box[\"x1\"], box[\"y1\"]\n",
        "        x2, y2 = box[\"x2\"], box[\"y2\"]\n",
        "        sub = image[y1:y2, x1:x2]\n",
        "        blur = cv2.blur(sub, (25, 25))\n",
        "        image[y1:y2, x1:x2] = blur\n",
        "\n",
        "    if output_image:\n",
        "        cv2.imwrite(output_image, image)\n",
        "        # print('Image has been saved successfully at', output_image, 'path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtjV3quB-ot1"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/drive/MyDrive/face-anonymization/model/face.pb'\n",
        "validation_path = '/content/drive/MyDrive/face-anonymization/val'\n",
        "anonymized_validation_path = '/content/drive/MyDrive/face-anonymization/val_anonymized'\n",
        "\n",
        "# columns:\n",
        "# - file\n",
        "\n",
        "# - deepface_age\n",
        "# - deepface_gender\n",
        "# - deepface_gender_confidence\n",
        "# - deepface_race\n",
        "# - deepface_race_confidence\n",
        "# - deepface_emotion\n",
        "# - deepface_emotion_confidence\n",
        "\n",
        "# - anonymized_deepface_age\n",
        "# - anonymized_deepface_gender\n",
        "# - anonymized_deepface_gender_confidence\n",
        "# - anonymized_deepface_race\n",
        "# - anonymized_deepface_race_confidence\n",
        "# - anonymized_deepface_emotion\n",
        "# - anonymized_deepface_emotion_confidence\n",
        "\n",
        "# - deepface_gender_man\n",
        "# - deepface_gender_woman\n",
        "# - deepface_race_asian\n",
        "# - deepface_race_white\n",
        "# - deepface_race_middle_eastern\n",
        "# - deepface_race_indian\n",
        "# - deepface_race_latino\n",
        "# - deepface_race_black\n",
        "# - deepface_emotion_angry\n",
        "# - deepface_emotion_fear\n",
        "# - deepface_emotion_neutral\n",
        "# - deepface_emotion_sad\n",
        "# - deepface_emotion_disgust\n",
        "# - deepface_emotion_happy\n",
        "# - deepface_emotion_surprise\n",
        "\n",
        "# - anonymized_deepface_gender_man\n",
        "# - anonymized_deepface_gender_woman\n",
        "# - anonymized_deepface_race_asian\n",
        "# - anonymized_deepface_race_white\n",
        "# - anonymized_deepface_race_middle_eastern\n",
        "# - anonymized_deepface_race_indian\n",
        "# - anonymized_deepface_race_latino\n",
        "# - anonymized_deepface_race_black\n",
        "# - anonymized_deepface_emotion_angry\n",
        "# - anonymized_deepface_emotion_fear\n",
        "# - anonymized_deepface_emotion_neutral\n",
        "# - anonymized_deepface_emotion_sad\n",
        "# - anonymized_deepface_emotion_disgust\n",
        "# - anonymized_deepface_emotion_happy\n",
        "# - anonymized_deepface_emotion_surprise\n",
        "\n",
        "# save results as dataframe\n",
        "\n",
        "# create dataframe\n",
        "import pandas as pd\n",
        "results = pd.DataFrame()\n",
        "\n",
        "# blur images in validation_path\n",
        "# show print statement for each 100 images\n",
        "i = 0\n",
        "for image in os.listdir(validation_path):\n",
        "\n",
        "    # DO ONLY FIRST 1000 IMAGES DUE TO COMPUTE LIMITATIONS\n",
        "    if i >= 1000:\n",
        "        break  # Exit loop after processing 1000 images\n",
        "\n",
        "    blur_faces_in_image(os.path.join(validation_path, image), model_path, os.path.join(anonymized_validation_path, image))\n",
        "    i += 1\n",
        "    if i % 100 == 0:\n",
        "        print('Reached image:', i)\n",
        "    # analyze both original image and anonymized image\n",
        "    try:\n",
        "      original_result = DeepFace.analyze(img_path=os.path.join(validation_path, image), enforce_detection=True)[0]\n",
        "      face_identified = 1\n",
        "    except Exception as e:\n",
        "      original_result = DeepFace.analyze(img_path=os.path.join(validation_path, image), enforce_detection=False)[0]\n",
        "      face_identified = 0\n",
        "    try:\n",
        "      anonymized_result = DeepFace.analyze(img_path=os.path.join(anonymized_validation_path, image), enforce_detection=True)[0]\n",
        "      anonymous_face_identified = 1\n",
        "    except Exception as e:\n",
        "      anonymized_result = DeepFace.analyze(img_path=os.path.join(anonymized_validation_path, image), enforce_detection=False)[0]\n",
        "      anonymous_face_identified = 0\n",
        "    verification_result = DeepFace.verify(os.path.join(validation_path, image),  os.path.join(anonymized_validation_path, image), distance_metric='euclidean_l2', enforce_detection=False)\n",
        "\n",
        "    # add results as a row to dataframe\n",
        "    # first, add file name, then add rest of attrbiutes\n",
        "    results = results.append(\n",
        "        {\n",
        "            'file': image,\n",
        "            'face_identified': face_identified,\n",
        "            'anonymous_face_identified': anonymous_face_identified,\n",
        "\n",
        "            'age': original_result['age'],\n",
        "            'anonymized_age': anonymized_result['age'],\n",
        "            'age_diff': original_result['age'] - anonymized_result['age'],\n",
        "\n",
        "            'gender_woman': original_result['gender']['Woman'],\n",
        "            'gender_man': original_result['gender']['Man'],\n",
        "            'dominant_gender': original_result['dominant_gender'],\n",
        "            'anonymized_gender_woman': anonymized_result['gender']['Woman'],\n",
        "            'anonymized_gender_man': anonymized_result['gender']['Man'],\n",
        "            'anonymized_dominant_gender': anonymized_result['dominant_gender'],\n",
        "            'gender_woman_diff': original_result['gender']['Woman'] - anonymized_result['gender']['Woman'],\n",
        "            'gender_man_diff': original_result['gender']['Man'] - anonymized_result['gender']['Man'],\n",
        "            'dominant_gender_diff': 1 if original_result['dominant_gender'] == anonymized_result['dominant_gender'] else 0,\n",
        "\n",
        "            'race_asian': original_result['race']['asian'],\n",
        "            'race_black': original_result['race']['black'],\n",
        "            'race_indian': original_result['race']['indian'],\n",
        "            'race_latino_hispanic': original_result['race']['latino hispanic'],\n",
        "            'race_middle_eastern': original_result['race']['middle eastern'],\n",
        "            'race_white': original_result['race']['white'],\n",
        "            'dominant_race': original_result['dominant_race'],\n",
        "            'anonymized_race_asian': anonymized_result['race']['asian'],\n",
        "            'anonymized_race_black': anonymized_result['race']['black'],\n",
        "            'anonymized_race_indian': anonymized_result['race']['indian'],\n",
        "            'anonymized_race_latino_hispanic': anonymized_result['race']['latino hispanic'],\n",
        "            'anonymized_race_middle_eastern': anonymized_result['race']['middle eastern'],\n",
        "            'anonymized_race_white': anonymized_result['race']['white'],\n",
        "            'anonymized_dominant_race': anonymized_result['dominant_race'],\n",
        "            'race_asian_diff': original_result['race']['asian'] - anonymized_result['race']['asian'],\n",
        "            'race_black_diff': original_result['race']['black'] - anonymized_result['race']['black'],\n",
        "            'race_indian_diff': original_result['race']['indian'] - anonymized_result['race']['indian'],\n",
        "            'race_latino_hispanic_diff': original_result['race']['latino hispanic'] - anonymized_result['race']['latino hispanic'],\n",
        "            'race_middle_eastern_diff': original_result['race']['middle eastern'] - anonymized_result['race']['middle eastern'],\n",
        "            'race_white_diff': original_result['race']['white'] - anonymized_result['race']['white'],\n",
        "            'dominant_race_diff': 1 if original_result['dominant_race'] == anonymized_result['dominant_race'] else 0,\n",
        "\n",
        "            'emotion_angry': original_result['emotion']['angry'],\n",
        "            'emotion_disgust': original_result['emotion']['disgust'],\n",
        "            'emotion_fear': original_result['emotion']['fear'],\n",
        "            'emotion_happy': original_result['emotion']['happy'],\n",
        "            'emotion_neutral': original_result['emotion']['neutral'],\n",
        "            'emotion_sad': original_result['emotion']['sad'],\n",
        "            'emotion_surprise': original_result['emotion']['surprise'],\n",
        "            'dominant_emotion': original_result['dominant_emotion'],\n",
        "            'anonymized_emotion_angry': anonymized_result['emotion']['angry'],\n",
        "            'anonymized_emotion_disgust': anonymized_result['emotion']['disgust'],\n",
        "            'anonymized_emotion_fear': anonymized_result['emotion']['fear'],\n",
        "            'anonymized_emotion_happy': anonymized_result['emotion']['happy'],\n",
        "            'anonymized_emotion_neutral': anonymized_result['emotion']['neutral'],\n",
        "            'anonymized_emotion_sad': anonymized_result['emotion']['sad'],\n",
        "            'anonymized_emotion_surprise': anonymized_result['emotion']['surprise'],\n",
        "            'anonymized_dominant_emotion': anonymized_result['dominant_emotion'],\n",
        "            'emotion_angry_diff': original_result['emotion']['angry'] - anonymized_result['emotion']['angry'],\n",
        "            'emotion_disgust_diff': original_result['emotion']['disgust'] - anonymized_result['emotion']['disgust'],\n",
        "            'emotion_fear_diff': original_result['emotion']['fear'] - anonymized_result['emotion']['fear'],\n",
        "            'emotion_happy_diff': original_result['emotion']['happy'] - anonymized_result['emotion']['happy'],\n",
        "            'emotion_neutral_diff': original_result['emotion']['neutral'] - anonymized_result['emotion']['neutral'],\n",
        "            'emotion_sad_diff': original_result['emotion']['sad'] - anonymized_result['emotion']['sad'],\n",
        "            'emotion_surprise_diff': original_result['emotion']['surprise'] - anonymized_result['emotion']['surprise'],\n",
        "            'dominant_emotion_diff': 1 if original_result['dominant_emotion'] == anonymized_result['dominant_emotion'] else 0,\n",
        "\n",
        "            'verified': verification_result['verified'],\n",
        "            'verified_distance': verification_result['distance'],\n",
        "\n",
        "        }, ignore_index=True)\n",
        "\n",
        "# save dataframe as csv\n",
        "results.to_csv('/content/drive/MyDrive/face-anonymization/results1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-21dmauZx-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5599be4-670b-4c3d-ef36-1ea37c693031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Race Accuracy: 56.67%\n",
            "Average Gender Accuracy: 82.16%\n",
            "Average Age Accuracy: 84.02%\n"
          ]
        }
      ],
      "source": [
        " #calculate accuracy post anonymization\n",
        " #are the attributes the same before and after anonymization\n",
        "def accuracy(results):\n",
        "  df = pd.DataFrame(results)\n",
        "\n",
        "  # Create age bins\n",
        "  age_bins = pd.cut(df['age'], bins=[0, 18, 35, 51, 120], labels=['0-17', '18-34', '35-50', '51+'])\n",
        "\n",
        "   # Filter out rows where face_identified or anonymous_face_identified are 0\n",
        "  df = df[(df['face_identified'] == 1) & (df['anonymous_face_identified'] == 1)]\n",
        "\n",
        "  # Create a new column indicating whether the age bin is the same pre and post-anonymization\n",
        "  df['same_age_bin'] = (pd.cut(df['age'], bins=[0, 18, 35, 51, 120], labels=['0-17', '18-34', '35-50', '51+']) ==\n",
        "                          pd.cut(df['anonymized_age'], bins=[0, 18, 35, 51, 120], labels=['0-17', '18-34', '35-50', '51+'])).astype(int)\n",
        "\n",
        "  same_race = df['dominant_race_diff'].sum()\n",
        "  same_gender = df['dominant_gender_diff'].sum()\n",
        "  same_age = df['same_age_bin'].sum()\n",
        "\n",
        "  total = len(df)\n",
        "\n",
        "  race_accuracy = (same_race / total) * 100\n",
        "  gender_accuracy = (same_gender / total) * 100\n",
        "  age_accuracy = (same_age / total) * 100\n",
        "\n",
        "  #print(f\"Race Accuracy: {race_accuracy:.2f}%\")\n",
        "  #print(f\"Gender Accuracy: {gender_accuracy:.2f}%\")\n",
        "  #print(f\"Age Accuracy: {age_accuracy:.2f}%\")\n",
        "\n",
        "  return race_accuracy, gender_accuracy, age_accuracy\n",
        "\n",
        "# List of file paths\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/face-anonymization/results1.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results2.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results3.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results4.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results5.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results6.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results7.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results8.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results9.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results10.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results11.csv',\n",
        "]\n",
        "\n",
        "# Initialize lists to store accuracy values\n",
        "race_accuracies = []\n",
        "gender_accuracies = []\n",
        "age_accuracies = []\n",
        "\n",
        "# Loop through file paths\n",
        "for file_path in file_paths:\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Call the accuracy function with the DataFrame\n",
        "    race_accuracy, gender_accuracy, age_accuracy = accuracy(df)\n",
        "\n",
        "    # Append accuracy values to the lists\n",
        "    race_accuracies.append(race_accuracy)  #white_accuracies.append(dictionary[white])\n",
        "    gender_accuracies.append(gender_accuracy)\n",
        "    age_accuracies.append(age_accuracy)\n",
        "\n",
        "# Calculate average accuracies\n",
        "average_race_accuracy = sum(race_accuracies) / len(race_accuracies)\n",
        "average_gender_accuracy = sum(gender_accuracies) / len(gender_accuracies)\n",
        "average_age_accuracy = sum(age_accuracies) / len(age_accuracies)\n",
        "\n",
        "# Print the average accuracies\n",
        "print(f\"Average Race Accuracy: {average_race_accuracy:.2f}%\")\n",
        "print(f\"Average Gender Accuracy: {average_gender_accuracy:.2f}%\")\n",
        "print(f\"Average Age Accuracy: {average_age_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eobYmgWUM9dR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4d98ae-a93f-4417-f14e-bf836153adf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy for Women Gender: 33.59%\n",
            "Average Accuracy for Man Gender: 96.20%\n",
            "Average Accuracy for Asian Race: 56.37%\n",
            "Average Accuracy for Black Race: 70.98%\n",
            "Average Accuracy for Indian Race: 43.72%\n",
            "Average Accuracy for Middle Eastern Race: 42.59%\n",
            "Average Accuracy for Latino Hispanic Race: 33.45%\n",
            "Average Accuracy for White Race: 60.71%\n"
          ]
        }
      ],
      "source": [
        "def statistical_parity(results):\n",
        "\n",
        "  # Convert the list of results to a DataFrame\n",
        "  df = pd.DataFrame(results)\n",
        "\n",
        "  # Filtering the DataFrame to exclude rows where either 'binary_column1' or 'binary_column2' is 0\n",
        "  df = df[(df['face_identified'] != 0) | (df['anonymous_face_identified'] != 0)]\n",
        "\n",
        "  # separate data for unprivileged and privileged group\n",
        "  unprivileged_group = df[df['dominant_gender'] == 'Woman']\n",
        "  privileged_group = df[df['dominant_gender'] == 'Man']\n",
        "\n",
        "  # count correct predictions for the dominant gender for each group\n",
        "  unprivileged_correct = unprivileged_group['dominant_gender_diff'].sum()\n",
        "  privileged_correct = privileged_group['dominant_gender_diff'].sum()\n",
        "\n",
        "  # count how many are in each group\n",
        "  unprivileged_total = len(unprivileged_group)\n",
        "  privileged_total = len(privileged_group)\n",
        "\n",
        "  # calculate proportions\n",
        "  unprivileged_accuracy = (unprivileged_correct/unprivileged_total) * 100\n",
        "  privileged_accuracy = (privileged_correct/privileged_total) * 100\n",
        "\n",
        "  # number of unprivileged correct over all correct\n",
        "  gender_unpriv_over_all = unprivileged_correct/(unprivileged_correct + privileged_correct)\n",
        "\n",
        "  races = ['asian', 'black', 'indian', 'latino hispanic', 'middle eastern', 'white']\n",
        "  race_accuracy_dict = {}  # Dictionary to store counts for each race\n",
        "\n",
        "  for race in races:\n",
        "    # Filter rows where the original 'dominant_race' is the current race\n",
        "    race_data = df[df['dominant_race'] == race]\n",
        "\n",
        "    # Filter rows where the original 'dominant_race' is the current race and 'dominant_race_diff' is 1\n",
        "    correct_race_data = df[(df['dominant_race'] == race) & (df['dominant_race_diff'] == 1)]\n",
        "\n",
        "    # Count the number of rows for the current race and correct matches\n",
        "    count_race = len(race_data)\n",
        "    count_correct_race = len(correct_race_data)\n",
        "\n",
        "    # calculate accuracy for the current race\n",
        "    if count_race > 0:  # Avoid division by zero\n",
        "        race_accuracy = (count_correct_race / count_race) * 100\n",
        "    else:\n",
        "        #print('no correct predictions')\n",
        "        race_accuracy = 0  # Set accuracy to 0 if count_race is 0\n",
        "\n",
        "    # Store counts for each race in the dictionary\n",
        "    race_accuracy_dict[race] = race_accuracy\n",
        "\n",
        "  return unprivileged_accuracy, privileged_accuracy, gender_unpriv_over_all, race_accuracy_dict\n",
        "\n",
        "# List of file paths\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/face-anonymization/results1.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results2.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results3.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results4.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results5.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results6.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results7.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results8.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results9.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results10.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results11.csv',\n",
        "]\n",
        "\n",
        "# Initialize lists to store accuracy values\n",
        "unprivileged_g_accuracies = []\n",
        "privileged_g_accuracies = []\n",
        "g_unpriv_over_all_accuracies = []\n",
        "\n",
        "asian_accuracies = []\n",
        "black_accuracies = []\n",
        "indian_accuracies = []\n",
        "middle_eastern_accuracies = []\n",
        "latino_hispanic_accuracies = []\n",
        "white_accuracies = []\n",
        "\n",
        "# Loop through file paths\n",
        "for file_path in file_paths:\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Call the accuracy function with the DataFrame\n",
        "    unprivileged_accuracy, privileged_accuracy, gender_unpriv_over_all, race_accuracy_dict = statistical_parity(df)\n",
        "    #print(race_accuracy_dict)\n",
        "    # Append accuracy values to the lists\n",
        "    unprivileged_g_accuracies.append(unprivileged_accuracy)\n",
        "    privileged_g_accuracies.append(privileged_accuracy)\n",
        "    g_unpriv_over_all_accuracies.append(gender_unpriv_over_all)\n",
        "    asian_accuracies.append(race_accuracy_dict['asian'])\n",
        "    black_accuracies.append(race_accuracy_dict['black'])\n",
        "    indian_accuracies.append(race_accuracy_dict['indian'])\n",
        "    middle_eastern_accuracies.append(race_accuracy_dict['middle eastern'])\n",
        "    latino_hispanic_accuracies.append(race_accuracy_dict['latino hispanic'])\n",
        "    white_accuracies.append(race_accuracy_dict['white'])\n",
        "\n",
        "# Calculate average accuracies\n",
        "a_unprivileged_acc = sum(unprivileged_g_accuracies) / len(unprivileged_g_accuracies)\n",
        "a_privileged_acc = sum(privileged_g_accuracies) / len(privileged_g_accuracies)\n",
        "a_unpriv_over_all_acc = sum(g_unpriv_over_all_accuracies) / len(g_unpriv_over_all_accuracies)\n",
        "\n",
        "a_asian_acc = sum(asian_accuracies) / len(asian_accuracies)\n",
        "a_black_acc = sum(black_accuracies) / len(black_accuracies)\n",
        "a_indian_acc = sum(indian_accuracies) / len(indian_accuracies)\n",
        "a_middle_eastern_acc = sum(middle_eastern_accuracies) / len(middle_eastern_accuracies)\n",
        "a_latino_hispanic_acc = sum(latino_hispanic_accuracies) / len(latino_hispanic_accuracies)\n",
        "a_white_acc = sum(white_accuracies) / len(white_accuracies)\n",
        "\n",
        "# Print the average accuracies\n",
        "print(f\"Average Accuracy for Women Gender: {a_unprivileged_acc:.2f}%\")\n",
        "print(f\"Average Accuracy for Man Gender: {a_privileged_acc:.2f}%\")\n",
        "#print(f\"Average (Woman Correct/Total Correct): {a_unpriv_over_all_acc:.2f}%\")\n",
        "\n",
        "print(f\"Average Accuracy for Asian Race: {a_asian_acc:.2f}%\")\n",
        "print(f\"Average Accuracy for Black Race: {a_black_acc:.2f}%\")\n",
        "print(f\"Average Accuracy for Indian Race: {a_indian_acc:.2f}%\")\n",
        "print(f\"Average Accuracy for Middle Eastern Race: {a_middle_eastern_acc:.2f}%\")\n",
        "print(f\"Average Accuracy for Latino Hispanic Race: {a_latino_hispanic_acc:.2f}%\")\n",
        "print(f\"Average Accuracy for White Race: {a_white_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# List of file paths\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/face-anonymization/results1.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results2.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results3.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results4.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results5.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results6.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results7.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results8.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results9.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results10.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results11.csv',\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through file paths and read CSV files into DataFrames\n",
        "for file_path in file_paths:\n",
        "    df = pd.read_csv(file_path)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into one\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "def calculate_intersectional_accuracy(df, gender, race, attribute_column):\n",
        "    intersectional_data = df[(df['dominant_gender'] == gender) & (df['dominant_race'] == race)]\n",
        "    if len(intersectional_data) > 0:\n",
        "        accuracy = (intersectional_data[attribute_column].sum() / len(intersectional_data)) * 100\n",
        "        return accuracy\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df = combined_df\n",
        "# List of unique genders and races\n",
        "genders = df['dominant_gender'].unique()\n",
        "races = df['dominant_race'].unique()\n",
        "\n",
        "# Initialize an empty dictionary to store intersectional accuracies for gender and race\n",
        "intersectional_accuracies_gender = {}\n",
        "intersectional_accuracies_race = {}\n",
        "\n",
        "# Loop through genders and races for gender accuracy\n",
        "for gender in genders:\n",
        "    for race in races:\n",
        "        accuracy = calculate_intersectional_accuracy(combined_df, gender, race, 'dominant_gender_diff')\n",
        "        intersectional_accuracies_gender[(gender, race)] = accuracy\n",
        "\n",
        "# Loop through genders and races for race accuracy\n",
        "for gender in genders:\n",
        "    for race in races:\n",
        "        accuracy = calculate_intersectional_accuracy(combined_df, gender, race, 'dominant_race_diff')\n",
        "        intersectional_accuracies_race[(gender, race)] = accuracy\n",
        "\n",
        "# Display the results for gender accuracy\n",
        "for (gender, race), accuracy in intersectional_accuracies_gender.items():\n",
        "    print(f\"Average gender accuracy for ({gender}, {race}) intersectional group: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Display the results for race accuracy\n",
        "for (gender, race), accuracy in intersectional_accuracies_race.items():\n",
        "    print(f\"Average race accuracy for ({gender}, {race}) intersectional group: {accuracy:.2f}%\")\n",
        "\n",
        "# Count the values for original 'dominant_gender' and 'dominant_race'\n",
        "original_gender_counts = df['dominant_gender'].value_counts()\n",
        "original_race_counts = df['dominant_race'].value_counts()\n",
        "\n",
        "# Count the values for anonymized 'anonymized_gender' and 'anonymized_race'\n",
        "anonymized_gender_counts = df['anonymized_dominant_gender'].value_counts()\n",
        "anonymized_race_counts = df['anonymized_dominant_race'].value_counts()\n",
        "\n",
        "# Display the results for original 'dominant_gender' counts\n",
        "print(\"\\nOriginal 'dominant_gender' counts:\")\n",
        "print(original_gender_counts)\n",
        "\n",
        "# Display the results for anonymized 'anonymized_gender' counts\n",
        "print(\"\\nAnonymized 'anonymized_gender' counts:\")\n",
        "print(anonymized_gender_counts)\n",
        "\n",
        "# Display the results for original 'dominant_race' counts\n",
        "print(\"\\nOriginal 'dominant_race' counts:\")\n",
        "print(original_race_counts)\n",
        "\n",
        "# Display the results for anonymized 'anonymized_race' counts\n",
        "print(\"\\nAnonymized 'anonymized_race' counts:\")\n",
        "print(anonymized_race_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riN8_OM0f5ES",
        "outputId": "8e61f16d-17d2-4fac-f126-04289b603d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average gender accuracy for (Man, asian) intersectional group: 96.31%\n",
            "Average gender accuracy for (Man, white) intersectional group: 96.74%\n",
            "Average gender accuracy for (Man, indian) intersectional group: 97.99%\n",
            "Average gender accuracy for (Man, middle eastern) intersectional group: 98.30%\n",
            "Average gender accuracy for (Man, latino hispanic) intersectional group: 97.27%\n",
            "Average gender accuracy for (Man, black) intersectional group: 98.41%\n",
            "Average gender accuracy for (Woman, asian) intersectional group: 44.87%\n",
            "Average gender accuracy for (Woman, white) intersectional group: 53.20%\n",
            "Average gender accuracy for (Woman, indian) intersectional group: 37.04%\n",
            "Average gender accuracy for (Woman, middle eastern) intersectional group: 47.01%\n",
            "Average gender accuracy for (Woman, latino hispanic) intersectional group: 34.64%\n",
            "Average gender accuracy for (Woman, black) intersectional group: 53.90%\n",
            "\n",
            "\n",
            "Average race accuracy for (Man, asian) intersectional group: 65.19%\n",
            "Average race accuracy for (Man, white) intersectional group: 73.71%\n",
            "Average race accuracy for (Man, indian) intersectional group: 52.01%\n",
            "Average race accuracy for (Man, middle eastern) intersectional group: 54.07%\n",
            "Average race accuracy for (Man, latino hispanic) intersectional group: 40.05%\n",
            "Average race accuracy for (Man, black) intersectional group: 82.11%\n",
            "Average race accuracy for (Woman, asian) intersectional group: 59.38%\n",
            "Average race accuracy for (Woman, white) intersectional group: 68.54%\n",
            "Average race accuracy for (Woman, indian) intersectional group: 30.37%\n",
            "Average race accuracy for (Woman, middle eastern) intersectional group: 52.14%\n",
            "Average race accuracy for (Woman, latino hispanic) intersectional group: 40.22%\n",
            "Average race accuracy for (Woman, black) intersectional group: 81.41%\n",
            "\n",
            "Original 'dominant_gender' counts:\n",
            "Man      8507\n",
            "Woman    2467\n",
            "Name: dominant_gender, dtype: int64\n",
            "\n",
            "Anonymized 'anonymized_gender' counts:\n",
            "Man      9579\n",
            "Woman    1395\n",
            "Name: anonymized_dominant_gender, dtype: int64\n",
            "\n",
            "Original 'dominant_race' counts:\n",
            "white              3238\n",
            "asian              2848\n",
            "black              2030\n",
            "latino hispanic    1237\n",
            "middle eastern      940\n",
            "indian              681\n",
            "Name: dominant_race, dtype: int64\n",
            "\n",
            "Anonymized 'anonymized_race' counts:\n",
            "white              3349\n",
            "asian              2738\n",
            "black              2500\n",
            "latino hispanic     988\n",
            "middle eastern      876\n",
            "indian              523\n",
            "Name: anonymized_dominant_race, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "def combine_dataframes(file_paths):\n",
        "    # Initialize an empty dataframe\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through file paths and concatenate dataframes\n",
        "    for file_path in file_paths:\n",
        "        df = pd.read_csv(file_path)\n",
        "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# List of file paths for training data\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/face-anonymization/results1.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results2.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results3.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results4.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results5.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results6.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results7.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results8.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results9.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results10.csv',\n",
        "    '/content/drive/MyDrive/face-anonymization/results11.csv',\n",
        "]\n",
        "\n",
        "# Combine dataframes for training data\n",
        "training_dataset = combine_dataframes(file_paths)\n",
        "\n",
        "# Display the distribution of gender and race in the training data\n",
        "distribution_table = training_dataset.groupby(['dominant_gender', 'dominant_race']).size().reset_index(name='Count')\n",
        "\n",
        "# Calculate the total count for all gender and race combinations\n",
        "total_count = distribution_table['Count'].sum()\n",
        "total_row = pd.DataFrame([[total_count]], columns=['Count'])\n",
        "distribution_table = pd.concat([distribution_table, total_row], ignore_index=True)\n",
        "\n",
        "table = tabulate(distribution_table, headers=[\"Count\"], tablefmt=\"pretty\")\n",
        "print(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysBVP7MIHqcw",
        "outputId": "6b404d18-9b6d-45c9-f7e9-807bc13f6390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+-----------------+-------+\n",
            "|    |       |                 | Count |\n",
            "+----+-------+-----------------+-------+\n",
            "| 0  |  Man  |      asian      | 2166  |\n",
            "| 1  |  Man  |      black      | 1761  |\n",
            "| 2  |  Man  |     indian      |  546  |\n",
            "| 3  |  Man  | latino hispanic |  879  |\n",
            "| 4  |  Man  | middle eastern  |  823  |\n",
            "| 5  |  Man  |      white      | 2332  |\n",
            "| 6  | Woman |      asian      |  682  |\n",
            "| 7  | Woman |      black      |  269  |\n",
            "| 8  | Woman |     indian      |  135  |\n",
            "| 9  | Woman | latino hispanic |  358  |\n",
            "| 10 | Woman | middle eastern  |  117  |\n",
            "| 11 | Woman |      white      |  906  |\n",
            "| 12 |  nan  |       nan       | 10974 |\n",
            "+----+-------+-----------------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine dataframes for training data\n",
        "training_dataset = combine_dataframes(file_paths)\n",
        "\n",
        "# Print the size of the resulting combined dataframe\n",
        "print(f\"Size of combined dataframe: {len(training_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HBPAyviiZv8",
        "outputId": "db1bd3fe-6acb-4e71-a054-914eafe53aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of combined dataframe: 10974\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}